{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers, diffusers\n",
    "transformers.CLIPTokenizer.from_pretrained(\"openai/clip-vit-large-patch14\").save_pretrained(\"./tokenizers/\")\n",
    "transformers.CLIPTextModel.from_pretrained(\"openai/clip-vit-large-patch14\").save_pretrained(\"./models/text/\")\n",
    "diffusers.UNet2DConditionModel.from_pretrained(\"prompthero/openjourney\", subfolder = \"unet\").save_pretrained(\"./models/unet/\")\n",
    "diffusers.AutoencoderKL.from_pretrained(\"prompthero/openjourney\", subfolder = \"vae\").save_pretrained(\"./models/vae/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, tqdm, PIL, numpy, datetime, diffusers, transformers\n",
    "def diffuse(prompt, takes = 1):\n",
    "    latents = scheduler.sigmas[0] * torch.randn(takes, 4, 64, 64)\n",
    "    index = 0\n",
    "    with torch.no_grad():\n",
    "        embeddings = torch.cat([text(tokenizer(takes * [\"\"], padding = \"max_length\", truncation = True, return_tensors = \"pt\").input_ids)[\"last_hidden_state\"], text(tokenizer(takes * [prompt], padding = \"max_length\", truncation = True, return_tensors = \"pt\").input_ids)[\"last_hidden_state\"]])\n",
    "        for value in tqdm.tqdm(scheduler.timesteps):\n",
    "            noise = unet(torch.cat([latents, latents]) / (scheduler.sigmas[index] ** 2 + 1) ** .5, value, embeddings)[\"sample\"].chunk(2)\n",
    "            latents = scheduler.step(11 * noise[1] - 10 * noise[0], value, latents)[\"prev_sample\"]\n",
    "            index += 1\n",
    "        index = 0\n",
    "        truncation = prompt[: 100]\n",
    "        images = PIL.Image.new(\"RGB\", [512 * takes, 512])\n",
    "        for value in (127.5 * vae.decode(latents / .18215)[\"sample\"].clamp(-1, 1).permute(0, 2, 3, 1).numpy() + 127.5).astype(numpy.uint8):\n",
    "            image = PIL.Image.fromarray(value)\n",
    "            image.save(f\"./images/{str(datetime.datetime.now()).replace(':', '.')}.{index} {truncation}.png\")\n",
    "            images.paste(image, [512 * index, 0])\n",
    "            index += 1\n",
    "    return images\n",
    "scheduler = diffusers.LMSDiscreteScheduler(beta_start = .00085, beta_end = .012, beta_schedule = \"scaled_linear\")\n",
    "scheduler.set_timesteps(28)\n",
    "tokenizer = transformers.CLIPTokenizer.from_pretrained(\"./tokenizers/\")\n",
    "text = transformers.CLIPTextModel.from_pretrained(\"./models/text/\")\n",
    "unet = diffusers.UNet2DConditionModel.from_pretrained(\"./models/unet/\")\n",
    "vae = diffusers.AutoencoderKL.from_pretrained(\"./models/vae/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffuse(\"masterpiece, best quality, abstract painting of a lush pond landscape, photorealistic, rtx on, 8k, by greg ratakowski\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
